{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1500633-b5f4-49e0-98d6-78976e0b195b",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00061859-71e8-4e0a-ad3f-3b41c2eeb4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tqdm.auto as tqdm\n",
    "import torch\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1a956d-5a42-4ed5-b568-a59f47e1854e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab(x: torch.Tensor) -> np.ndarray:\n",
    "    \"\"\"Convert a torch Tensor to numpy array\"\"\"\n",
    "    return x.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ffa82f-1c8b-4f29-9f9b-6d858d345c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap(x):\n",
    "    \"\"\"Wrap angle into range [-pi, pi]\"\"\"\n",
    "    return (x + np.pi) % (2*np.pi) - np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de06828-4ca5-456f-9d22-e5d3e12be82b",
   "metadata": {},
   "source": [
    "# Action\n",
    "We will consider a simple family of theories on a space of two angles $(\\theta_1, \\theta_2)$. The general form of the action is\n",
    "$$\n",
    "S(\\theta_1, \\theta_2; \\alpha, \\beta) := -\\beta \\cos(\\theta_1 - \\theta_2) - \\alpha \\cos(\\theta_1) + \\alpha \\cos(\\theta_2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4caf25-0f30-4f0b-9f19-e3d06d33881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action(th, *, alpha, beta):\n",
    "    \"\"\"family of actions on two angles\"\"\"\n",
    "    assert th.shape[-1] == 2\n",
    "    th1, th2 = th[...,0] ,th[...,1]\n",
    "    return (\n",
    "        -beta * torch.cos(th1 - th2) - alpha * torch.cos(th1)\n",
    "        + alpha * torch.cos(th2)\n",
    "    )\n",
    "\n",
    "def make_action(alpha, beta):\n",
    "    return lambda th: action(th, alpha=alpha, beta=beta)\n",
    "\n",
    "# some target parameters\n",
    "beta_target = 3.0\n",
    "alpha_target = 1.0\n",
    "target_action = make_action(alpha_target, beta_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2061c979-7cf6-47c4-80a9-167042dca95e",
   "metadata": {},
   "source": [
    "It will be useful to have samples from the target distribution. There are many possible way to build this ensemble, here we just do a crude importance sampling with a single resampling step according to computed weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa393efb-99ac-4365-9df7-47a05b6eed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_inds(weights):\n",
    "    \"\"\"resample indices according to weights\"\"\"\n",
    "    p = np.copy(weights)\n",
    "    p /= np.sum(p)\n",
    "    return np.random.choice(len(weights), p=p, size=len(weights))\n",
    "\n",
    "def sample(batch_size, action, *, beta0):\n",
    "    \"\"\"importance sampling to get ground truth data\"\"\"\n",
    "    shape = (batch_size,)\n",
    "    dist = torch.distributions.VonMises(0.0, beta0)\n",
    "    delta = dist.sample(shape)\n",
    "    S0 = dist.log_prob(delta)\n",
    "    th1 = 2*np.pi*torch.rand(size=shape)\n",
    "    th2 = (th1 - delta) % (2*np.pi)\n",
    "    th = torch.stack([th1, th2], axis=-1)\n",
    "    logw = -action(th) + S0\n",
    "    logw -= torch.logsumexp(logw, dim=0)\n",
    "    weight = np.exp(grab(logw))\n",
    "    # resample\n",
    "    inds = sample_inds(weight)\n",
    "    return th[inds]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c631fcd9-26c0-4375-8277-027837e697b1",
   "metadata": {},
   "source": [
    "**EXERCISE:** Implement a more principled sampling function, like MCMC, rejection sampling, or inverse CDF sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b5c058-1c68-480b-afb6-4d33eabe76fa",
   "metadata": {},
   "source": [
    "Set up some utilities to plot distributions of samples or analytic action over the two-dimensional plane of angles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d3d59d-57b7-4bcf-95f2-4c5c2f8e0f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_th_grid(steps):\n",
    "    th = torch.linspace(-np.pi, np.pi, steps=steps)\n",
    "    th = (th[1:]+th[:-1])/2\n",
    "    th = torch.stack(torch.meshgrid([th, th], indexing='ij'), axis=-1)\n",
    "    return th\n",
    "def plot_dist(action, *, ax, nsteps=60):\n",
    "    th = make_th_grid(nsteps)\n",
    "    S = action(th)\n",
    "    th = grab(th)\n",
    "    ax.contourf(th[...,0], th[...,1], np.exp(-grab(S)))\n",
    "def plot_samples(th, *, ax, nbins=60):\n",
    "    bins = np.linspace(-np.pi, np.pi, num=nbins+1)\n",
    "    th = wrap(grab(th))\n",
    "    ax.hist2d(th[...,0], th[...,1], bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d627fa5-4f1a-40d7-b20a-80506a140b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = sample(100000, action=target_action, beta0=0.5)\n",
    "fig, axes = plt.subplots(1,2, figsize=(6,3))\n",
    "plot_dist(target_action, ax=axes[0])\n",
    "plot_samples(samples, ax=axes[1])\n",
    "for ax in axes:\n",
    "    ax.set_aspect(1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca99d8-8ae4-4692-9a1f-0875a5c373a5",
   "metadata": {},
   "source": [
    "# Action coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766315c1-d73e-4cf3-b1c3-1890990d8773",
   "metadata": {},
   "source": [
    "For this simple theory, we can expand any action (our target, or intermediate learned actions) in a Fourier basis:\n",
    "$$\n",
    "\\tilde{S}(k_1, k_2) \\sim \\int_0^{2\\pi} \\frac{d\\theta_1}{2\\pi} \\frac{d\\theta_2}{2\\pi} e^{-i k \\cdot \\theta} S(\\theta).\n",
    "$$\n",
    "We can think of these coefficients as some kind of Wilson coefficients in a systematic expansion. It will provide a way to see how we move through the (infinite-dimensional) space of distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a81b31-3ad9-4daa-93fe-f3e7e60cc04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_coeffs_grid(S):\n",
    "    \"\"\"extract Wilson-like coeffs using the Fourier transform\"\"\"\n",
    "    Sk = np.fft.ifft2(S)\n",
    "    c = Sk[0,0]\n",
    "    a1 = Sk[0,1] + Sk[0,-1]\n",
    "    a2 = Sk[1,0] + Sk[-1,0]\n",
    "    b1 = Sk[1,1] + Sk[-1,-1]\n",
    "    b2 = Sk[1,-1] + Sk[-1,1]\n",
    "    return dict(c=c, a1=a1, a2=a2, b1=b1, b2=b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89498bcc-3387-44e2-8cd0-cc267312b9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_coeffs(action):\n",
    "    th = make_th_grid(200)\n",
    "    S = grab(action(th))\n",
    "    return measure_coeffs_grid(S)\n",
    "# for example, the coefficients of our target action extract the\n",
    "# alpha, -alpha, and beta terms\n",
    "measure_coeffs(target_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e46c4a-a8c7-45ad-83a4-b6794adad34e",
   "metadata": {},
   "source": [
    "# Annealing / trivializing flow\n",
    "Let's first look at the path through the space of distributions described by annealing / the trivializing flow. This is just linear interpolation in the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b2a275-1250-422d-b2ae-7192040d23c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.linspace(0, 1, num=51)\n",
    "actions = [\n",
    "    make_action(t*alpha_target, t*beta_target)\n",
    "    for t in ts\n",
    "]\n",
    "coeffs = [measure_coeffs(S) for S in actions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95eb73b-42fc-4ceb-b204-b46ae5d7330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coeffs(ts, coeffs, x='a1', y='b2', *, ax, cmap, marker='.', label=None):\n",
    "    pts = np.stack([(coeff[x], coeff[y]) for coeff in coeffs], axis=1)\n",
    "    cmap = plt.get_cmap(cmap)\n",
    "    ax.scatter(*pts, marker=marker, s=3, color=cmap(ts), label=label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31dc730-380f-4e41-8d67-175424edebae",
   "metadata": {},
   "source": [
    "Unsurprisingly, the extracted Wilson coefficients are linearly interpolated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcd2b0b-47d2-472c-b474-367213e220a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(3, 3), tight_layout=True)\n",
    "plot_coeffs(ts, coeffs, ax=ax, cmap='Reds_r', marker='o', label='Triv flow')\n",
    "ax.set_xlabel(r'$\\alpha$')\n",
    "ax.set_ylabel(r'$\\beta$')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0551ebcf-90ea-4c71-8dd1-7a73d8f06f01",
   "metadata": {},
   "source": [
    "# Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aac52b-eebf-4d0e-a985-eaf5f55a6f11",
   "metadata": {},
   "source": [
    "The diffusion path requires implementing the **Langevin SDE**. We can use a simple Euler-Maruyama integrator, starting from samples from the target distribution to simulate the forward process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54246508-40d9-4415-bde5-34e4d673d7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(th, *, g=1.5, nsteps=1000, save_freq=10):\n",
    "    dt = 1/nsteps\n",
    "    ts = [0.0]\n",
    "    samples = [wrap(th.clone())]\n",
    "    for i in tqdm.tqdm(range(nsteps)):\n",
    "        t = (i+1)*dt\n",
    "        dW = np.sqrt(2*dt*g**2)*torch.randn_like(th)\n",
    "        th += dW\n",
    "        if (i+1) % save_freq == 0:\n",
    "            samples.append(wrap(th.clone()))\n",
    "            ts.append(t)\n",
    "    return dict(samples=samples, ts=ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5aa378-297b-4d12-951f-4502287ce79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_res = forward(samples.clone())\n",
    "diff_samples = diff_res['samples']\n",
    "diff_ts = diff_res['ts']\n",
    "bins = np.linspace(-np.pi, np.pi, num=11)\n",
    "diff_coeffs = [measure_coeffs_grid(\n",
    "    -np.log(np.histogram2d(th[...,0], th[...,1], bins=bins, density=True)[0])\n",
    ") for th in diff_samples]\n",
    "print(f'{len(diff_ts)=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc76d496-86ab-4a87-81b2-f43c7e698b70",
   "metadata": {},
   "source": [
    "As the forward process proceeds, **noise is added** until we converge towards the **uniform distribution**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a345395-16fa-45b2-9020-575026a9c630",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(8, 3), tight_layout=True)\n",
    "inds = [0, 25, 50, 100]\n",
    "for ind, ax in zip(inds, axes):\n",
    "    t = diff_ts[ind]\n",
    "    plot_samples(diff_samples[ind], ax=ax)\n",
    "    ax.set_title(rf'$t = {t}$')\n",
    "    ax.set_aspect(1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89704853-1b16-491d-bbbf-a175b2ea254b",
   "metadata": {},
   "source": [
    "Compared to the annealing path, diffusion takes a **non-linear path in the space of couplings**. It terminates at (or close to) the uniform distribution with zero couplings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5542190b-5d46-4672-86b9-6c104543a99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(3, 3), tight_layout=True)\n",
    "plot_coeffs(ts, coeffs, ax=ax, cmap='Reds_r', marker='o', label='Triv flow')\n",
    "plot_coeffs(diff_ts, diff_coeffs, ax=ax, cmap='Blues_r', marker='s', label='Diffusion')\n",
    "ax.set_xlabel(r'$\\alpha$')\n",
    "ax.set_ylabel(r'$\\beta$')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d93005-a6af-4adb-ab3e-27ee64ae27e2",
   "metadata": {},
   "source": [
    "# Normalizing flow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d3fd07-a6c4-49dc-b6bf-56ebeaa60799",
   "metadata": {},
   "source": [
    "Finally, we implement a simple **hard-coded flow** (no machine learning yet!). To evaluate the flow, we just use a simple Euler integrator. The coefficients of the flow are arbitrarily tuned to approximately reproduce the target distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9042e5ba-f89a-4b95-87c1-8d0ff87297ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow(th, nsteps=1000, save_freq=10):\n",
    "    dt = 1/nsteps\n",
    "    def velocity(th, t):\n",
    "        th1, th2 = th[...,0], th[...,1]\n",
    "        return (\n",
    "            5*t*(1-t) * torch.stack([\n",
    "                -torch.sin(th1 - th2), -torch.sin(th2 - th1)], axis=-1)\n",
    "            + t**2 * torch.stack([-torch.sin(th1), torch.sin(th2)], axis=-1)\n",
    "        )\n",
    "    samples = [wrap(th.clone())]\n",
    "    ts = [0.0]\n",
    "    for i in tqdm.tqdm(range(nsteps)):\n",
    "        t = (i+1)*dt\n",
    "        v = velocity(th, t)\n",
    "        th += dt * v\n",
    "        if (i+1) % save_freq == 0:\n",
    "            samples.append(wrap(th.clone()))\n",
    "            ts.append(t)\n",
    "    return dict(samples=samples, ts=ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586cd69a-f078-4e13-a17c-13d56d7295ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_th = 2*np.pi*torch.rand(size=(100000, 2))\n",
    "flow_res = flow(prior_th)\n",
    "flow_ts = flow_res['ts']\n",
    "flow_samples = flow_res['samples']\n",
    "bins = np.linspace(-np.pi, np.pi, num=11)\n",
    "flow_coeffs = [measure_coeffs_grid(\n",
    "    -np.log(np.histogram2d(th[...,0], th[...,1], bins=bins, density=True)[0])\n",
    ") for th in flow_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23206cf5-7bcb-48f0-8941-86010bc1d897",
   "metadata": {},
   "source": [
    "The samples converge towards something similar to our target distribution, as shown in the histograms of the density below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13998131-36f8-4e20-a175-4cea29ba9290",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(8, 3), tight_layout=True)\n",
    "inds = [0, 25, 50, 100]\n",
    "for ind, ax in zip(inds, axes):\n",
    "    t = flow_ts[ind]\n",
    "    plot_samples(flow_samples[ind], ax=ax)\n",
    "    ax.set_title(rf'$t = {t}$')\n",
    "    ax.set_aspect(1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c118fe22-7641-4f38-8011-717fc668a6db",
   "metadata": {},
   "source": [
    "**EXERCISE:** Compute the probability density of the flow by integrating the divergence of the flow field. Compare this against the sample density above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e37dd-1201-4046-af42-7e9045f216f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(3, 3), tight_layout=True)\n",
    "plot_coeffs(ts, coeffs, ax=ax, cmap='Reds_r', marker='o', label='Triv flow')\n",
    "plot_coeffs(diff_ts, diff_coeffs, ax=ax, cmap='Blues_r', marker='s', label='Diffusion')\n",
    "plot_coeffs(flow_ts, flow_coeffs, ax=ax, cmap='Greens_r', marker='^', label='Flow')\n",
    "ax.set_xlabel(r'$\\alpha$')\n",
    "ax.set_ylabel(r'$\\beta$')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
